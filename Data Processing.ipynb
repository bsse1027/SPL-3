{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39121c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d968d93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./pre_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b936b192",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc20865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_df(csv_path, nrows = None):\n",
    "    json_cols = ['device', 'geoNetwork', 'totals', 'trafficSource']\n",
    "    df = pd.read_csv(csv_path,\n",
    "                     #converters are dict of functions for converting values in certain columns. Keys can either be integers or column labels.\n",
    "                     #json.loads() method can be used to parse a valid JSON string and convert it into a Python Dictionary.\n",
    "                     #It is mainly used for deserializing native string, byte, or byte array which consists of JSON data into Python Dictionary.\n",
    "                     converters = {col: json.loads for col in json_cols},                                                                         \n",
    "                         dtype = {'fullVisitorId': 'str'}, # Important!!\n",
    "                         nrows = nrows)\n",
    "    for col in json_cols:\n",
    "        # for each column, flatten data frame such that the values of a single col are spread in different cols\n",
    "        # This will use subcol as names of flat_col.columns\n",
    "        flat_col = json_normalize(df[col])\n",
    "        # Name the columns in this flatten data frame as col.subcol for tracability\n",
    "        flat_col.columns = [f\"{col}.{subcol}\" for subcol in flat_col.columns]\n",
    "        # Drop the json_col and instead add the new flat_col\n",
    "        df = df.drop(col, axis = 1).merge(flat_col, right_index = True, left_index = True)\n",
    "    return df\n",
    "\n",
    "\n",
    "csv_test_path = './test_v2.csv'\n",
    "test = load_df(csv_test_path, nrows = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb8fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115d79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify non opearting countries \n",
    "lowCountries=[]\n",
    "hitWithCountry = {}\n",
    "sum = 0\n",
    "cnt = test['geoNetwork.country'].value_counts(sort=True)\n",
    "print(cnt)\n",
    "for i in range(0, cnt.size):\n",
    "    sum = sum + cnt[i]\n",
    "\n",
    "#Identify the Non Operating Countries\n",
    "\n",
    "for i in range(0, cnt.size):\n",
    "    #print(f\"Country Name: {cnt.index[i]} Frequency: {(cnt[i]/sum)*100}%\" )\n",
    "    if((cnt[i]/sum)*100 < 0.01):\n",
    "        lowCountries.append(cnt.index[i]) \n",
    "len(lowCountries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration for Rule 1\n",
    "import matplotlib.pyplot as plt\n",
    "#categories = df['Predictions'].to_numpy()\n",
    "colormap = np.array(['g', 'r'])\n",
    "hits1 = {}\n",
    "test['totals.hits'] = pd.to_numeric(test['totals.hits'])\n",
    "for indx in range(test.index.start, test.index.stop):\n",
    "    #print(indx)\n",
    "    country = test.at[indx, 'geoNetwork.country']\n",
    "    oneIndex = (test.at[indx,'hits'])\n",
    "    #hitsInfo = ast.literal_eval(oneIndex)\n",
    "    #print(hitsInfo)\n",
    "    if country in lowCountries:\n",
    "        if country not in hits1.keys():\n",
    "            hits1[country] = (test.at[indx, 'totals.hits'])\n",
    "        elif country in hits1.keys():\n",
    "            hits1[country] = hits1[country] + (test.at[indx, 'totals.hits'])\n",
    "len(hits1)\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f = plt.scatter(hits1.keys(), hits1.values())\n",
    "f = plt.xlabel('country')\n",
    "f = plt.ylabel('Total Hits')\n",
    "f = plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08004356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##First Rule : If total hits of a session from NON Opearting/rare countries is outlier means 1.5 IQR from Q3\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import ast\n",
    "\n",
    "cnt=0\n",
    "sum=0\n",
    "lowCountries=[]\n",
    "hitWithCountry = {}\n",
    "cnt = test['geoNetwork.country'].value_counts(sort=True)\n",
    "\n",
    "for i in range(0, cnt.size):\n",
    "    sum = sum + cnt[i]\n",
    "\n",
    "#Identify the Non Operating Countries\n",
    "\n",
    "for i in range(0, cnt.size):\n",
    "    #print(f\"Country Name: {cnt.index[i]} Frequency: {(cnt[i]/sum)*100}%\" )\n",
    "    if((cnt[i]/sum)*100 < 0.01):\n",
    "        lowCountries.append(cnt.index[i]) \n",
    "    \n",
    "\n",
    "inputCountries = test.at[0,'geoNetwork.country']\n",
    "\n",
    "test['totals.hits'] = pd.to_numeric(test['totals.hits'])\n",
    "data = test['totals.hits']\n",
    "np.median(data)\n",
    "upper_q = np.percentile(data, 75)\n",
    "lower_q = np.percentile(data, 25)\n",
    "iqr = upper_q - lower_q\n",
    "upper_whisker = data[data<=upper_q+1.5*iqr].max()\n",
    "lower_whisker = data[data>=lower_q-1.5*iqr].min()\n",
    "#print(upper_whisker)\n",
    "\n",
    "for indx in range(test.index.start, test.index.stop):\n",
    "    #print(indx)\n",
    "    country = test.at[indx, 'geoNetwork.country']\n",
    "    oneIndex = (test.at[indx,'hits'])\n",
    "    #hitsInfo = ast.literal_eval(oneIndex)\n",
    "    #print(hitsInfo)\n",
    "    if country in lowCountries:\n",
    "        hit = test.at[indx, 'totals.hits']\n",
    "        if int(hit) > upper_whisker:\n",
    "            test.loc[indx, 'isAnomaly'] = 1\n",
    "#            print(f\"Index Number : {indx} Anomalous traffic Info: {country} Total Hits : {int(hit)} Visit Date:{test.at[indx, 'date']}\")\n",
    "#             for ind in range(0, len(hitsInfo)):\n",
    "#                 print(f\"Hit Number: {hitsInfo[ind]['hitNumber']} Visited Page: {hitsInfo[ind]['appInfo']['screenName']} Keyword: {test.at[indx, 'trafficSource.keyword']}\")\n",
    "        #print(f\"Country Name: {country} --> Total hits: {hit}\")\n",
    "#         if country in hitWithCountry.keys():\n",
    "#             hitWithCountry[country] += 1\n",
    "#         else:\n",
    "#             hitWithCountry[country]=1\n",
    "\n",
    "#newArr = test['hits'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c3fb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "oneIndex = (test.at[0,'hits'])\n",
    "result = ast.literal_eval(oneIndex)\n",
    "#print(type(result))\n",
    "for ind in range(0, len(result)):\n",
    "    print(f\"Hit Number: {result[ind]['hitNumber']} Visited Page: {result[ind]['appInfo']['screenName']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2529dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration for Rule 2\n",
    "import matplotlib.pyplot as plt\n",
    "#categories = df['Predictions'].to_numpy()\n",
    "colormap = np.array(['g', 'r'])\n",
    "views1 = {}\n",
    "test['totals.pageviews'] = pd.to_numeric(test['totals.pageviews'])\n",
    "for indx in range(test.index.start, test.index.stop):\n",
    "    #print(indx)\n",
    "    country = test.at[indx, 'geoNetwork.country']\n",
    "    #oneIndex = (test.at[indx,'totals.pageviews'])\n",
    "    #hitsInfo = ast.literal_eval(oneIndex)\n",
    "    #print(hitsInfo)\n",
    "    if country in lowCountries:\n",
    "        if country not in views1.keys():\n",
    "            views1[country] = (test.at[indx, 'totals.pageviews'])\n",
    "        elif country in views1.keys():\n",
    "            views1[country] = views1[country] + (test.at[indx, 'totals.hits'])\n",
    "len(views1)\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f = plt.scatter(views1.keys(), views1.values())\n",
    "f = plt.xlabel('country')\n",
    "f = plt.ylabel('Total PageViews')\n",
    "f = plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff3bebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rule 2 : if total pageViews from a session is absurdly higher from RareCountries\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "sum = 0\n",
    "test['totals.pageviews'] = pd.to_numeric(test['totals.pageviews'])\n",
    "##Replace NaN Values with Zero\n",
    "test['totals.pageviews'].fillna(value = 0, inplace = True)\n",
    "data = test['totals.pageviews']\n",
    "upper_q = np.percentile(data, 75)\n",
    "lower_q = np.percentile(data, 25)\n",
    "iqr = upper_q - lower_q\n",
    "upper_whisker = data[data<=upper_q+1.5*iqr].max()\n",
    "lower_whisker = data[data>=lower_q-1.5*iqr].min()\n",
    "lower_whisker\n",
    "\n",
    "## Rule based on the Total PageView\n",
    "for ind in range(len(test)):\n",
    "    pageView = test.at[ind , 'totals.pageviews']\n",
    "    country = test.at[ind , 'geoNetwork.country']\n",
    "    if pageView > upper_whisker and country in lowCountries:\n",
    "        test.loc[i, 'isAnomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a625845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration for Rule 3\n",
    "import matplotlib.pyplot as plt\n",
    "#categories = df['Predictions'].to_numpy()\n",
    "colormap = np.array(['g', 'r'])\n",
    "\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f = plt.scatter(test['geoNetwork.country'], test['totals.pageviews'])\n",
    "f = plt.xlabel('country')\n",
    "f = plt.ylabel('Total PageViews')\n",
    "f = plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24a6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Rule 3 : if total pageViews from a session is absurdly higher from any Country\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "sum = 0\n",
    "\n",
    "data = test['totals.pageviews']\n",
    "upper_q = np.percentile(data, 75)\n",
    "lower_q = np.percentile(data, 25)\n",
    "iqr = upper_q - lower_q\n",
    "upper_whisker = data[data<=upper_q+1.5*iqr].max()\n",
    "lower_whisker = data[data>=lower_q-1.5*iqr].min()\n",
    "lower_whisker\n",
    "\n",
    "## Rule based on the Total PageView\n",
    "for i in range(len(test)):\n",
    "    pageView = test.loc[i , 'totals.pageviews']\n",
    "    country = test.loc[i , 'geoNetwork.country']\n",
    "    if pageView > upper_whisker*10:\n",
    "        test.loc[i, 'isAnomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c57637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = test['totals.pageviews']\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75173720",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in zip(test.fullVisitorId.duplicated().index, test.fullVisitorId.duplicated()):\n",
    "    if j == True:\n",
    "        print(test.loc[i, 'fullVisitorId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3f4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "test['totals.hits'] = pd.to_numeric(test['totals.hits'])\n",
    "mean = test['totals.hits'].mean()\n",
    "std = test['totals.hits'].std()\n",
    "maximum = test['totals.hits'].max()\n",
    "\n",
    "#plt.boxplot(test['totals.hits'])\n",
    "#plt.xlim(xmin=0, xmax = 501)\n",
    "#plt.show()\n",
    "data = test['totals.hits']\n",
    "np.median(data)\n",
    "upper_q = np.percentile(data, 75)\n",
    "lower_q = np.percentile(data, 25)\n",
    "iqr = upper_q - lower_q\n",
    "upper_whisker = data[data<=upper_q+1.5*iqr].max()\n",
    "lower_whisker = data[data>=lower_q-1.5*iqr].min()\n",
    "upper_whisker\n",
    "data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660af0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Exploration for Rule 4\n",
    "import matplotlib.pyplot as plt\n",
    "#categories = df['Predictions'].to_numpy()\n",
    "colormap = np.array(['g', 'r'])\n",
    "tos1 = {}\n",
    "test['totals.timeOnSite'] = pd.to_numeric(test['totals.timeOnSite'])\n",
    "for indx in range(test.index.start, test.index.stop):\n",
    "    #print(indx)\n",
    "    country = test.at[indx, 'geoNetwork.country']\n",
    "    #oneIndex = (test.at[indx,'totals.pageviews'])\n",
    "    #hitsInfo = ast.literal_eval(oneIndex)\n",
    "    #print(hitsInfo)\n",
    "    if country in lowCountries:\n",
    "        if country not in tos1.keys():\n",
    "            tos1[country] = (test.at[indx, 'totals.pageviews'])\n",
    "        elif country in tos1.keys():\n",
    "            tos1[country] = tos1[country] + (test.at[indx, 'totals.hits'])\n",
    "len(tos1)\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f = plt.scatter(tos1.keys(), tos1.values())\n",
    "f = plt.xlabel('country')\n",
    "f = plt.ylabel('Session Duration')\n",
    "f = plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a4d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 4: Session duration is outlier for non operating countries\n",
    "## total.timeOnSite means session duration of a session\n",
    "import matplotlib.pyplot as plt\n",
    "sum = 0\n",
    "test['totals.timeOnSite'] = pd.to_numeric(test['totals.timeOnSite'])\n",
    "test['totals.timeOnSite'].fillna(value = 0, inplace = True)\n",
    "data = test['totals.timeOnSite']\n",
    "upper_q = np.percentile(data, 75)\n",
    "lower_q = np.percentile(data, 25)\n",
    "iqr = upper_q - lower_q\n",
    "upper_whisker = data[data<=upper_q+1.5*iqr].max()\n",
    "lower_whisker = data[data>=lower_q-1.5*iqr].min()\n",
    "for i in range(len(test)):\n",
    "    timeOnSite = test.at[i, 'totals.timeOnSite']\n",
    "    country = test.at[i, 'geoNetwork.country']\n",
    "    if timeOnSite > upper_whisker and country in lowCountries:\n",
    "        test.loc[i, 'isAnomaly'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c224906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determining how many users come to our system in an hour to create a baseline for rule 5\n",
    "\n",
    "#test['visitStartTime'] = pd.to_datetime(test['visitStartTime'], unit='s')\n",
    "usersWithDate = {}\n",
    "test['date'] = pd.to_numeric(test['date'])\n",
    "test = test.sort_values(by = 'visitStartTime')\n",
    "test = test.reset_index(drop = True)\n",
    "#print(test)\n",
    "timeDiff = test['visitStartTime'].max() - test['visitStartTime'].min()\n",
    "dayDiff = timeDiff / 86400\n",
    "dayDiff = dayDiff.round()\n",
    "print(dayDiff)\n",
    "UsersPerDay = (test['fullVisitorId'].count() / dayDiff).round()\n",
    "UsersPerHour = (UsersPerDay/24).round()\n",
    "hourCount = 86400/24\n",
    "startTime = test.loc[0 , 'visitStartTime']\n",
    "sumOfUsers = 0\n",
    "userCounts=[]\n",
    "for itr in range(len(test)):\n",
    "    #print(test.loc[itr, 'visitStartTime'])\n",
    "    if(test.loc[itr, 'visitStartTime'] > (startTime + 3600)):\n",
    "        startTime = test.loc[itr, 'visitStartTime']\n",
    "        usersWithDate[startTime] = sumOfUsers\n",
    "        userCounts.append(sumOfUsers)\n",
    "        sumOfUsers = 0\n",
    "    sumOfUsers = sumOfUsers+1\n",
    "len(userCounts)\n",
    "#test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f8d8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(userCounts)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.boxplot(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2ebaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#categories = df['Predictions'].to_numpy()\n",
    "colormap = np.array(['g', 'r'])\n",
    "\n",
    "f = plt.figure(figsize=(12, 4))\n",
    "f = plt.scatter(usersWithDate.keys(), usersWithDate.values())\n",
    "f = plt.xlabel('date')\n",
    "f = plt.ylabel('usersHour')\n",
    "f = plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207d9f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rule 5 : Detect Anomalous users generating higher volume of traffic in an hour\n",
    "sum = 0\n",
    "anomalousHours = []\n",
    "times = {}\n",
    "data = list(usersWithDate.values())\n",
    "upper_q = np.percentile(data, 75)\n",
    "lower_q = np.percentile(data, 25)\n",
    "iqr = upper_q - lower_q\n",
    "upper_whisker = upper_q+1.5*iqr\n",
    "lower_whisker = lower_q-1.5*iqr\n",
    "for i,j in usersWithDate.items():\n",
    "    if j > upper_whisker:\n",
    "        anomalousHours.append(i)\n",
    "\n",
    "for i in range(len(anomalousHours)):\n",
    "    for j in range(len(test)):\n",
    "        endTime = anomalousHours[i]\n",
    "        startTime = endTime - 3600\n",
    "        if test.loc[j, 'visitStartTime'] >=startTime and test.loc[j, 'visitStartTime'] <= endTime:\n",
    "            if j not in times:\n",
    "                times[j] = (test.loc[j, 'totals.hits'])\n",
    "            elif j not in times:\n",
    "                times[j] = times[j] + (test.loc[j, 'totals.hits'])\n",
    "    data = list(times.values())\n",
    "    upper_q = np.percentile(data, 75)\n",
    "    lower_q = np.percentile(data, 25)\n",
    "    iqr = upper_q - lower_q\n",
    "    upper_whisker = upper_q+1.5*iqr\n",
    "    lower_whisker = lower_q-1.5*iqr\n",
    "#     print(upper_whisker)\n",
    "    for a, b in times.items():\n",
    "        if b > upper_whisker:\n",
    "            test.loc[a, 'isAnomaly'] = 1\n",
    "\n",
    "#sum\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a891e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1395"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['isAnomaly'].fillna(value = 0, inplace = True)\n",
    "aomalousSessions = test[test['isAnomaly'] == 1]\n",
    "len(aomalousSessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b97ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "aomalousSessions.to_csv('./out.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9018c046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rule 6: SQL Injection Type Search Keywords having quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfc1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = test[test['trafficSource.keyword'].notna()]\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11744e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"May 15\n",
      "\"May 15\n",
      "\"May 15\n"
     ]
    }
   ],
   "source": [
    "new = new[new['trafficSource.keyword'] != '(not set)']\n",
    "new = new[new['trafficSource.keyword'] != '(not provided)']\n",
    "new = new[new['trafficSource.keyword'] != '(automatic matching)']\n",
    "for index in new.index:\n",
    "    if \"\\\"\" in new.loc[index,'trafficSource.keyword']:\n",
    "        print(new.loc[index,'trafficSource.keyword'])\n",
    "        test.loc[a, 'isAnomaly'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d51add10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1396"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aomalousSessions = test[test['isAnomaly'] == 1]\n",
    "len(aomalousSessions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
